{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/bc/32/9b88a1634c5ae2b0b0fdd092254bde59bb93c9e4e779ef56d6ca9900bd67/tiktoken-0.5.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.5.2-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/d3/10/6f2d5f8635d7714ad97ce6ade7a643358c4f3e45cde4ed12b7150734a8f3/regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 503.7 kB/s eta 0:00:00\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Obtaining dependency information for requests>=2.26.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/b6/7c/8debebb4f90174074b827c63242c23851bdf00a532489fba57fef3416e40/charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading tiktoken-0.5.2-cp312-cp312-win_amd64.whl (785 kB)\n",
      "   ---------------------------------------- 0.0/785.8 kB ? eta -:--:--\n",
      "   ---------------- ---------------------- 327.7/785.8 kB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 716.8/785.8 kB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  778.2/785.8 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  778.2/785.8 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 785.8/785.8 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.0/269.0 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.6/104.6 kB ? eta 0:00:00\n",
      "Installing collected packages: urllib3, regex, charset-normalizer, requests, tiktoken\n",
      "Successfully installed charset-normalizer-3.3.2 regex-2023.10.3 requests-2.31.0 tiktoken-0.5.2 urllib3-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)'))': /packages/bc/32/9b88a1634c5ae2b0b0fdd092254bde59bb93c9e4e779ef56d6ca9900bd67/tiktoken-0.5.2-cp312-cp312-win_amd64.whl.metadata\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:/Users/Anirudh/Desktop/company/gptforcolumnmapping/prompt_with_data_prepared (1).jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Encoding',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_tiktoken',\n",
       " 'core',\n",
       " 'encoding_for_model',\n",
       " 'encoding_name_for_model',\n",
       " 'get_encoding',\n",
       " 'list_encoding_names',\n",
       " 'load',\n",
       " 'model',\n",
       " 'registry']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tiktoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 187.9 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.0/1.5 MB 196.9 kB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.1/1.5 MB 504.4 kB/s eta 0:00:03\n",
      "     -------------- ------------------------- 0.5/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.0/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anirudh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.3.2 nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anirudh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    # Tokenize the text using nltk\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Count the number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    # Return the count\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        json_data = json.loads(line)\n",
    "        \n",
    "        # Assuming 'prompt' and 'completion' are keys in the dictionary\n",
    "        prompt_text = json_data.get('prompt', '')\n",
    "        completion_text = json_data.get('completion', '')\n",
    "\n",
    "        # Count tokens for prompt and completion\n",
    "        prompt_tokens = count_tokens(prompt_text)\n",
    "        completion_tokens = count_tokens(completion_text)\n",
    "\n",
    "        total_tokens += prompt_tokens + completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of tokens in C:/Users/Anirudh/Desktop/company/gptforcolumnmapping/prompt_with_data_prepared (1).jsonl: 7948\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimated number of tokens in {file_path}: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
