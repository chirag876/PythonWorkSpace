import pandas as pd
from fuzzywuzzy import fuzz, process
import json

# Function to load mapping configurations from a JSON file
def manage_mapping_from_config(config_path):
    # Open and read the JSON configuration file
    with open(config_path, 'r') as file:
        manual_mappings = json.load(file)
    # Reverse the mapping to be source_column -> destination_column for ease of access
    reversed_mappings = {src_col: dest for dest, src_cols in manual_mappings.items() for src_col in src_cols}
    return reversed_mappings

# Function to match column names using fuzzy matching
def manage_matching_column_from_fuzzy(source_df, destination_df, mapped_from_config):
    # Start with manually mapped columns
    mapping = {src: dest for src, dest in mapped_from_config.items() if src in source_df.columns}
    # Find the best fuzzy match for each unmapped source column in the destination columns
    for src_col in source_df.columns:
        if src_col not in mapping:
            best_match, score = process.extractOne(src_col, destination_df.columns, scorer=fuzz.token_sort_ratio)
            # Accept the match if the score is 80 or higher
            if score >= 80:
                mapping[src_col] = best_match
    return mapping

# Function to match columns by content similarity using fuzzy matching
def manage_matching_column_from_data_fuzzy(source_df, destination_df, mapped_columns):
    # Set a similarity threshold for renaming columns
    similarity_threshold = 70
    
    # Iterate over each column in the source DataFrame
    for src_col in source_df.columns:
        # Only proceed with source columns that haven't been mapped yet
        if src_col not in mapped_columns:
            # Drop null values and check if the source column has any non-null data
            if not source_df[src_col].dropna().empty:
                # Calculate the mode (most common value) of the source column
                src_common_value = source_df[src_col].dropna().mode()
                # If the mode calculation returns at least one value, proceed
                if not src_common_value.empty:
                    # Take the first mode value if there are multiple
                    src_common_value = src_common_value[0]
                    # Initialize variables to keep track of the best matching column and score
                    best_match = None
                    best_score = 0
                    # Iterate over each column in the destination DataFrame
                    for dest_col in destination_df.columns:
                        # Only consider destination columns that haven't been mapped yet
                        if dest_col not in mapped_columns.values():
                            # Get unique non-null values from the destination column
                            dest_common_values = destination_df[dest_col].dropna().unique()
                            # Iterate over each unique value in the destination column
                            for dest_value in dest_common_values:
                                # Calculate the similarity score between the source and destination values
                                similarity_score = fuzz.partial_ratio(str(src_common_value), str(dest_value))
                                # If this score is the highest so far, update the best match and score
                                if similarity_score > best_score:
                                    best_score = similarity_score
                                    best_match = dest_col
                    # If the best score is above the threshold, add the mapping to the mapped_columns dictionary
                    if best_score >= similarity_threshold:
                        mapped_columns[src_col] = best_match

    # Return the updated mapping dictionary
    return mapped_columns

# Function to fill in unmapped columns with default values
def fill_unmapped_columns(destination_df, mapped_columns):
    # Loop through destination columns and fill unmapped columns with defaults
    for dest_col in destination_df.columns:
        if dest_col not in mapped_columns.values():
            # Fill integer columns with 0 and other types with 'N/A'
            if pd.api.types.is_integer_dtype(destination_df[dest_col]):
                destination_df[dest_col].fillna(0, inplace=True)
            else:
                destination_df[dest_col].fillna('N/A', inplace=True)

# Function to create the output DataFrame and the schema DataFrame
def export_data_from_input_to_output(source_df, destination_df, mapped_columns):
    # Fill in unmapped columns in the destination DataFrame
    fill_unmapped_columns(destination_df, mapped_columns)

    # Initialize an empty DataFrame for the output with the same index as the source DataFrame
    output_df = pd.DataFrame(index=source_df.index)

    # Initialize a list to store schema data
    schema_data = []

    # Iterate over all columns in the destination DataFrame
    for dest_col in destination_df.columns:
        # Find the corresponding source column from the mapped columns, if it exists
        src_col = next((k for k, v in mapped_columns.items() if v == dest_col), None)

        # If a mapping exists, use the data from the source DataFrame for the output
        if src_col:
            output_df[dest_col] = source_df[src_col]
        # Otherwise, use the data from the destination DataFrame (which has been filled)
        else:
            output_df[dest_col] = destination_df[dest_col]

        # Append the mapping to the schema data list
        schema_data.append({
            'Output Column Name': dest_col,
            'Input Column Name': src_col if src_col else 'N/A'
        })

    # Create the schema DataFrame from the schema data list
    schema_df = pd.DataFrame(schema_data)

    return output_df, schema_df


# Main function to orchestrate the mapping and data merging process
def main(source_path, benchmark_path, output_path, schema_path, config_path):
    # Load the source and benchmark data from the provided CSV files
    source_df = pd.read_csv(source_path, encoding='cp1252')
    benchmark_df = pd.read_csv(benchmark_path, encoding='cp1252')

    # Load manual mappings from the configuration file
    manual_mappings = manage_mapping_from_config(config_path)
    # Perform fuzzy matching on column names
    mapped_columns = manage_matching_column_from_fuzzy(source_df, benchmark_df, manual_mappings)
    # Perform fuzzy matching on column data content
    mapped_columns = manage_matching_column_from_data_fuzzy(source_df, benchmark_df, mapped_columns)

    # Export the mapped data and schema to CSV files
    output_df, schema_df = export_data_from_input_to_output(source_df, benchmark_df, mapped_columns)
    schema_df.to_csv(schema_path, index=False)  # Save the schema DataFrame
    output_df.to_csv(output_path, index=False)  # Save the output DataFrame

    return output_df, schema_df

# Define paths to the input and output files
source_path = '/content/data_1__input.csv'
benchmark_path = '/content/benchmark.csv'
output_path = '/content/data_1__output.csv'
schema_path = '/content/data_1__schema.csv'
config_path = '/content/config.json'

# Run the main function with the specified file paths
output_df = main(source_path, benchmark_path, output_path, schema_path, config_path)
